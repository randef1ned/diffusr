[{"path":"https://diffusr.yinchun.su/VERSIONS.html","id":null,"dir":"","previous_headings":"","what":"Versions","title":"Versions","text":"news versioning look inst/NEWS.","code":""},{"path":"https://diffusr.yinchun.su/VERSIONS.html","id":"author","dir":"","previous_headings":"","what":"Author","title":"Versions","text":"Simon Dirmeier simon.dirmeier@gmx.de","code":""},{"path":"https://diffusr.yinchun.su/articles/diffusr.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"The diffusr tutorial","text":"diffusr implements algorithms network diffusion Markov random walks restarts weighted neighbor classification. Network diffusion studied extensively bioinformatics, e.g. field cancer gene prioritization. Network diffusion algorithms generally spread information form node weights along edges graph nodes. weights can example interpreted temperature, initial amount water, activation neurons brain, location random surfer internet. information (node weights) iteratively propagated nodes equilibrium state stop criterion occurs.","code":""},{"path":"https://diffusr.yinchun.su/articles/diffusr.html","id":"tutorial","dir":"Articles","previous_headings":"","what":"Tutorial","title":"The diffusr tutorial","text":"First load package:","code":"library(diffusr)"},{"path":"https://diffusr.yinchun.su/articles/diffusr.html","id":"markov-random-walks","dir":"Articles","previous_headings":"Tutorial","what":"Markov random walks","title":"The diffusr tutorial","text":"Markov random walk restarts calculates stationary distribution: \\[\\begin{equation} \\mathbf{p}_{t+1} = (1 - r) \\mathbf{W}  \\mathbf{p}_t + r \\mathbf{p}_0, \\end{equation}\\] \\(r \\(0,1)\\) restart probability Markov chain, \\(\\mathbf{W}\\) column-normalized stochastic matrix (normalization ) \\(\\mathbf{p}_0\\) starting distribution Markov chain. calculate iterative updates, also possible math using nullspace matrix (comes later). want use Markov random walks just try something like : stationary distribution changed quite bit starting distribution: can also use matrix p0: later case, random walk done columns p0 separately.","code":"# count of nodes   n <- 5   # starting distribution (has to sum to one)   p0    <- as.vector(rmultinom(1, 1, prob=rep(.2, n)))   # adjacency matrix (either normalized or not)   graph <- matrix(abs(rnorm(n*n)), n, n)   # computation of stationary distribution   pt    <- random.walk(p0, graph) print(t(p0)) ##      [,1] [,2] [,3] [,4] [,5] ## [1,]    0    0    0    0    1 print(t(pt)) ##      p.inf     transition.matrix ## [1,] numeric,5 numeric,25 p0 <- matrix(c(p0, runif(20)), nrow=n)    pt <- random.walk(p0, graph)    pt ## $p.inf ## [1] 0.14254159 0.11347180 0.06874839 0.12056554 0.55467267 ##  ## $transition.matrix ##            [,1]       [,2]        [,3]        [,4]      [,5] ## [1,] 0.00000000 0.27874857 0.006399332 0.015076331 0.4528753 ## [2,] 0.06674785 0.00000000 0.008989360 0.561236552 0.2689155 ## [3,] 0.08275131 0.05586213 0.000000000 0.420766454 0.1237506 ## [4,] 0.52249611 0.29829941 0.685367238 0.000000000 0.1544586 ## [5,] 0.32800473 0.36708989 0.299244069 0.002920663 0.0000000"},{"path":"https://diffusr.yinchun.su/articles/diffusr.html","id":"analytical-vs-iterative-solution","dir":"Articles","previous_headings":"Tutorial > Markov random walks","what":"Analytical vs iterative solution","title":"The diffusr tutorial","text":"last section computed iterative solution stationary distribution. can also choose analytically. case need take inverse transition matrix might lead numerical instability, though. However, usually runs faster iterative version.","code":"pt <- random.walk(p0, graph, do.analytical=TRUE)    pt ## $p.inf ## [1] 0.14254237 0.11347719 0.06875152 0.12056067 0.55466825 ##  ## $transition.matrix ##            [,1]       [,2]        [,3]        [,4]      [,5] ## [1,] 0.00000000 0.27874857 0.006399332 0.015076331 0.4528753 ## [2,] 0.06674785 0.00000000 0.008989360 0.561236552 0.2689155 ## [3,] 0.08275131 0.05586213 0.000000000 0.420766454 0.1237506 ## [4,] 0.52249611 0.29829941 0.685367238 0.000000000 0.1544586 ## [5,] 0.32800473 0.36708989 0.299244069 0.002920663 0.0000000"},{"path":"https://diffusr.yinchun.su/articles/diffusr.html","id":"nearest-neighbors","dir":"Articles","previous_headings":"Tutorial","what":"Nearest neighbors","title":"The diffusr tutorial","text":"Diffusion using nearest neighbors done traversing (weighted) graph take neighbors node certain depths graph reached. find shortest paths using priority queues: Let’s see nodes got:","code":"# count of nodes   n <- 10   # indexes(integer) of nodes for which neighbors should be searched   node.idxs <- c(1L, 5L)   # the adjaceny matrix (does not need to be symmetric)   graph <- rbind(cbind(0, diag(n-1)), 0)   # compute the neighbors until depth 3   neighs <- nearest.neighbors(node.idxs, graph, 3) print(neighs) ## $`1` ## [1] 2 3 4 ##  ## $`5` ## [1] 6 7 8"},{"path":"https://diffusr.yinchun.su/articles/diffusr.html","id":"heat-diffusion","dir":"Articles","previous_headings":"Tutorial","what":"Heat diffusion","title":"The diffusr tutorial","text":"Laplacian heat diffusion process calculates heat distribution graph specific time \\(t\\): \\[\\begin{equation} h_i(t) = h_i(0)\\exp(-\\lambda_i t) \\end{equation}\\] \\(\\mathbf{h}_0\\) initial heat distribution, \\(\\mathbf{h}_t\\) heat distribution time \\(t\\) \\(\\boldsymbol \\lambda\\) eigenvalues graph. can use Laplacian heat diffusion process like : results: , p0 can also matrix:","code":"# count of nodes   n <- 5   # starting distribution (has to sum to one)   h0    <- as.vector(rmultinom(1, 1, prob=rep(.2, n)))   # adjacency matrix (either normalized or not)   graph <- matrix(abs(rnorm(n*n)), n, n)   # computation of stationary distribution   ht    <- heat.diffusion(h0, graph) print(t(h0)) ##      [,1] [,2] [,3] [,4] [,5] ## [1,]    0    0    0    1    0 print(t(ht)) ##           [,1]       [,2]       [,3]      [,4]       [,5] ## [1,] 0.1093149 0.06323093 0.07643613 0.6224157 0.02010177 h0 <- matrix(c(h0, runif(20)), nrow=n)    ht <- heat.diffusion(h0, graph)    ht ##            [,1]      [,2]      [,3]      [,4]      [,5] ## [1,] 0.10931495 0.6380647 0.6828742 0.2792684 0.7283391 ## [2,] 0.06323093 0.4224313 0.6443288 0.4156627 0.2915234 ## [3,] 0.07643613 0.3234764 0.5038881 0.4129662 0.6290378 ## [4,] 0.62241573 0.3985255 0.5551638 0.5128568 0.5322090 ## [5,] 0.02010177 0.4469769 0.6970196 0.4035154 0.7450455"},{"path":"https://diffusr.yinchun.su/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Simon Dirmeier. Author, maintainer.","code":""},{"path":"https://diffusr.yinchun.su/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Dirmeier S (2024). diffusr: Network Diffusion Algorithms. R package version 0.2.1, https://github.com/randef1ned/diffusr.","code":"@Manual{,   title = {diffusr: Network Diffusion Algorithms},   author = {Simon Dirmeier},   year = {2024},   note = {R package version 0.2.1},   url = {https://github.com/randef1ned/diffusr}, }"},{"path":"https://diffusr.yinchun.su/index.html","id":"diffusr-","dir":"","previous_headings":"","what":"Network Diffusion Algorithms","title":"Network Diffusion Algorithms","text":"Network diffusion algorithms R.","code":""},{"path":"https://diffusr.yinchun.su/index.html","id":"introduction","dir":"","previous_headings":"","what":"Introduction","title":"Network Diffusion Algorithms","text":"diffusr implements several algorithms network diffusion Markov random walks restarts weighted neighbor classification. Network diffusion studied extensively bioinformatics, e.g. field cancer gene prioritization. Network diffusion algorithms generally spread information, e.g. encoded node weights, along edges graph nodes. weights can example interpreted temperature, initial amount water, activation neurons brain, location random surfer internet. information (node weights) iteratively propagated nodes equilibrium state stop criterion occurs.","code":""},{"path":"https://diffusr.yinchun.su/index.html","id":"before-installation","dir":"","previous_headings":"","what":"Before installation","title":"Network Diffusion Algorithms","text":"installation, recommended install Intel oneAPI Math Kernel Library (oneMKL) optimize computational performance linear algebra. Windows users can download oneMKL Intel’s website install default directory. default directory : C:\\Program Files (x86)\\Intel\\oneAPI. Debian users can download oneMKL using apt Debian non-free repo: using Intel repo: Fedora users can download oneMKL using dnf:","code":"# Install oneMKL version 2020.4.304-4 sudo apt install intel-mkl-full # Set up the repository and signed the entry wget -O- https://apt.repos.intel.com/intel-gpg-keys/GPG-PUB-KEY-INTEL-SW-PRODUCTS.PUB \\ | gpg --dearmor | sudo tee /usr/share/keyrings/oneapi-archive-keyring.gpg > /dev/null echo \"deb [signed-by=/usr/share/keyrings/oneapi-archive-keyring.gpg] https://apt.repos.intel.com/oneapi all main\" | sudo tee /etc/apt/sources.list.d/oneAPI.list # Update the package list sudo apt update # Install the latest oneMKL (version 2024.0) sudo apt install intel-oneapi-mkl # Create dnf repository file tee > /tmp/oneAPI.repo << EOF [oneAPI] name=Intel® oneAPI repository baseurl=https://yum.repos.intel.com/oneapi enabled=1 gpgcheck=1 repo_gpgcheck=1 gpgkey=https://yum.repos.intel.com/intel-gpg-keys/GPG-PUB-KEY-INTEL-SW-PRODUCTS.PUB EOF sudo mv /tmp/oneAPI.repo /etc/yum.repos.d # Install the latest oneMKL (version 2024.0) sudo dnf install intel-oneapi-mkl"},{"path":"https://diffusr.yinchun.su/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Network Diffusion Algorithms","text":"Install diffusr using: Alternatively use latest version github:","code":"install.packages(\"diffusr\") devtools::install_github(\"randef1ned/diffusr\", build_vignettes = TRUE)"},{"path":"https://diffusr.yinchun.su/index.html","id":"usage","dir":"","previous_headings":"","what":"Usage","title":"Network Diffusion Algorithms","text":"Load package using library(diffusr). provide vignette package can called using: vignette(\"diffusr\"). Basically know.","code":""},{"path":"https://diffusr.yinchun.su/index.html","id":"author","dir":"","previous_headings":"","what":"Author","title":"Network Diffusion Algorithms","text":"Simon Dirmeier simon.dirmeier@gmx.de","code":""},{"path":"https://diffusr.yinchun.su/reference/assert_dgCMatrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Check if the sparse matrix valid — assert_dgCMatrix","title":"Check if the sparse matrix valid — assert_dgCMatrix","text":"Check sparse matrix valid","code":""},{"path":"https://diffusr.yinchun.su/reference/assert_dgCMatrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check if the sparse matrix valid — assert_dgCMatrix","text":"","code":"assert_dgCMatrix(adj_matrix, non_negative = TRUE)"},{"path":"https://diffusr.yinchun.su/reference/assert_dgCMatrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check if the sparse matrix valid — assert_dgCMatrix","text":"adj_matrix sparse matrix check non_negative Check non negative vlues","code":""},{"path":"https://diffusr.yinchun.su/reference/diffusr-package.html","id":null,"dir":"Reference","previous_headings":"","what":"diffusr — diffusr-package","title":"diffusr — diffusr-package","text":"Network diffusion algorithms R.","code":""},{"path":"https://diffusr.yinchun.su/reference/diffusr-package.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"diffusr — diffusr-package","text":"Tong, H., Faloutsos, C., & Pan, J. Y. (2006), Fast random walk restart applications. Koehler, S., Bauer, S., Horn, D., & Robinson, P. N. (2008), Walking interactome prioritization candidate disease genes. American Journal Human Genetics Bonacich, P. (1987), Power centrality: family measures. American Journal Sociology Leiserson, M. D., Vandin, F., Wu, H. T., Dobson, J. R., Eldridge, J. V., Thomas, J. L., ... & Lawrence, M. S. (2015), Pan-cancer network analysis identifies combinations rare somatic mutations across pathways protein complexes. Nature genetics https://en.wikipedia.org/wiki/Laplacian_matrix https://en.wikipedia.org/wiki/Heat_equation","code":""},{"path":"https://diffusr.yinchun.su/reference/diffusr-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"diffusr — diffusr-package","text":"Simon Dirmeier simon.dirmeier@gmx.de","code":""},{"path":"https://diffusr.yinchun.su/reference/heat.diffusion.html","id":null,"dir":"Reference","previous_headings":"","what":"Graph diffusion using a heat diffusion process on a Laplacian matrix. — heat.diffusion","title":"Graph diffusion using a heat diffusion process on a Laplacian matrix. — heat.diffusion","text":"amount starting heat gets distribution using   Laplacian matrix graph. Every iteration (time interval) \\(t\\)   heat streams starting nodes surrounding nodes.","code":""},{"path":"https://diffusr.yinchun.su/reference/heat.diffusion.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Graph diffusion using a heat diffusion process on a Laplacian matrix. — heat.diffusion","text":"","code":"heat.diffusion(h0, graph, t = 0.5, ...)"},{"path":"https://diffusr.yinchun.su/reference/heat.diffusion.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Graph diffusion using a heat diffusion process on a Laplacian matrix. — heat.diffusion","text":"h0 \\(n \\times p\\)-dimensional numeric non-negative matrix (dgCMatrix, vector) starting temperatures graph (\\(n \\times n\\))-dimensional numeric non-negative adjacence matrix representing graph t time point heat measured ... additional parameters","code":""},{"path":"https://diffusr.yinchun.su/reference/heat.diffusion.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Graph diffusion using a heat diffusion process on a Laplacian matrix. — heat.diffusion","text":"returns heat every node numeric vector","code":""},{"path":"https://diffusr.yinchun.su/reference/heat.diffusion.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Graph diffusion using a heat diffusion process on a Laplacian matrix. — heat.diffusion","text":"https://en.wikipedia.org/wiki/Laplacian_matrix https://en.wikipedia.org/wiki/Heat_equation","code":""},{"path":"https://diffusr.yinchun.su/reference/heat.diffusion.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Graph diffusion using a heat diffusion process on a Laplacian matrix. — heat.diffusion","text":"","code":"# count of nodes n <- 5 # starting distribution (has to sum to one) h0 <- as.vector(rmultinom(1, 1, prob=rep(.2, n))) # adjacency matrix (either normalized or not) graph <- matrix(abs(rnorm(n*n)), n, n) # computation of stationary distribution heat <- heat.diffusion(h0, graph)"},{"path":"https://diffusr.yinchun.su/reference/hub.correction.html","id":null,"dir":"Reference","previous_headings":"","what":"Correct for hubs in an adjacency matrix — hub.correction","title":"Correct for hubs in an adjacency matrix — hub.correction","text":"Correct hubs adjacency matrix","code":""},{"path":"https://diffusr.yinchun.su/reference/hub.correction.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Correct for hubs in an adjacency matrix — hub.correction","text":"","code":"hub.correction(obj)"},{"path":"https://diffusr.yinchun.su/reference/hub.correction.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Correct for hubs in an adjacency matrix — hub.correction","text":"obj matrix (dgCMatrix) hubs corrected","code":""},{"path":"https://diffusr.yinchun.su/reference/hub.correction.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Correct for hubs in an adjacency matrix — hub.correction","text":"returns matrix ( dgCMatrix) hub correction","code":""},{"path":"https://diffusr.yinchun.su/reference/hub.correction.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Correct for hubs in an adjacency matrix — hub.correction","text":"","code":"W <- matrix(abs(rnorm(10000)), 100, 100) cor.hub <- hub.correction(W)"},{"path":"https://diffusr.yinchun.su/reference/is.dgCMatrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Check if a matrix is dgCMatrix class — is.dgCMatrix","title":"Check if a matrix is dgCMatrix class — is.dgCMatrix","text":"Check matrix dgCMatrix class","code":""},{"path":"https://diffusr.yinchun.su/reference/is.dgCMatrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check if a matrix is dgCMatrix class — is.dgCMatrix","text":"","code":"is.dgCMatrix(mat)"},{"path":"https://diffusr.yinchun.su/reference/is.dgCMatrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check if a matrix is dgCMatrix class — is.dgCMatrix","text":"mat matrix check","code":""},{"path":"https://diffusr.yinchun.su/reference/is.dgCMatrix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check if a matrix is dgCMatrix class — is.dgCMatrix","text":"boolean variable","code":""},{"path":"https://diffusr.yinchun.su/reference/nearest.neighbors.html","id":null,"dir":"Reference","previous_headings":"","what":"Graph diffusion using nearest neighbors — nearest.neighbors","title":"Graph diffusion using nearest neighbors — nearest.neighbors","text":"every node set nodes graph gets traversed along node's shortest paths neighbors. Nearest neighbors added maximum depth \\(k\\) reached. settings \\(k\\) neighbors distance, neighbors returned.","code":""},{"path":"https://diffusr.yinchun.su/reference/nearest.neighbors.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Graph diffusion using nearest neighbors — nearest.neighbors","text":"","code":"nearest.neighbors(nodes, graph, k = 1L, ...)"},{"path":"https://diffusr.yinchun.su/reference/nearest.neighbors.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Graph diffusion using nearest neighbors — nearest.neighbors","text":"nodes \\(n\\)-dimensional integer vector node indexes (1-based) algorithm applied iteratively graph (\\(n \\times n\\))-dimensional numeric non-negative adjacence matrix (dgCMatrix, vector) representing graph k depth nearest neighbor search, e.g. depth graph traversal ... additional parameters","code":""},{"path":"https://diffusr.yinchun.su/reference/nearest.neighbors.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Graph diffusion using nearest neighbors — nearest.neighbors","text":"returns kNN nodes list integer vectors node indexes","code":""},{"path":"https://diffusr.yinchun.su/reference/nearest.neighbors.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Graph diffusion using nearest neighbors — nearest.neighbors","text":"","code":"# count of nodes n <- 10 # indexes (integer) of nodes for which neighbors should be searched node.idxs <- c(1L, 5L) # the adjaceny matrix (does not need to be symmetric) graph <- rbind(cbind(0, diag(n-1)), 0) # compute the neighbors until depth 3 neighs <- nearest.neighbors(node.idxs, graph, 3)"},{"path":"https://diffusr.yinchun.su/reference/normalize.laplacian.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate the Laplacian of a matrix — normalize.laplacian","title":"Calculate the Laplacian of a matrix — normalize.laplacian","text":"Calculate Laplacian matrix","code":""},{"path":"https://diffusr.yinchun.su/reference/normalize.laplacian.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate the Laplacian of a matrix — normalize.laplacian","text":"","code":"normalize.laplacian(obj, ...)"},{"path":"https://diffusr.yinchun.su/reference/normalize.laplacian.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate the Laplacian of a matrix — normalize.laplacian","text":"obj matrix (dgCMatrix) Laplacian calculated ... additional params","code":""},{"path":"https://diffusr.yinchun.su/reference/normalize.laplacian.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate the Laplacian of a matrix — normalize.laplacian","text":"returns Laplacian","code":""},{"path":"https://diffusr.yinchun.su/reference/normalize.laplacian.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate the Laplacian of a matrix — normalize.laplacian","text":"","code":"W <- matrix(abs(rnorm(10000)), 100, 100) lapl.W <- normalize.laplacian(W)"},{"path":"https://diffusr.yinchun.su/reference/normalize.stochastic.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a stochastically normalized matrix/vector — normalize.stochastic","title":"Create a stochastically normalized matrix/vector — normalize.stochastic","text":"Create stochastically normalized matrix/vector","code":""},{"path":"https://diffusr.yinchun.su/reference/normalize.stochastic.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a stochastically normalized matrix/vector — normalize.stochastic","text":"","code":"normalize.stochastic(obj, ...)"},{"path":"https://diffusr.yinchun.su/reference/normalize.stochastic.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a stochastically normalized matrix/vector — normalize.stochastic","text":"obj matrix (dgCMatrix, vector) stochstically normalized ... additional params","code":""},{"path":"https://diffusr.yinchun.su/reference/normalize.stochastic.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a stochastically normalized matrix/vector — normalize.stochastic","text":"returns normalized matrix/vector)","code":""},{"path":"https://diffusr.yinchun.su/reference/normalize.stochastic.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a stochastically normalized matrix/vector — normalize.stochastic","text":"","code":"W <- matrix(abs(rnorm(10000)), 100, 100) stoch.W <- normalize.stochastic(W) #> normalizing column vectors!"},{"path":"https://diffusr.yinchun.su/reference/random.walk.html","id":null,"dir":"Reference","previous_headings":"","what":"Graph diffusion using a Markov random walk — random.walk","title":"Graph diffusion using a Markov random walk — random.walk","text":"Markov Random Walk takes inital distribution \\(p_0\\) calculates stationary distribution . diffusion process regulated restart probability \\(r\\) controls often MRW jumps back initial values.","code":""},{"path":"https://diffusr.yinchun.su/reference/random.walk.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Graph diffusion using a Markov random walk — random.walk","text":"","code":"random.walk(   p0,   graph,   r = 0.5,   niter = 10000,   thresh = 1e-04,   do.analytical = FALSE,   correct.for.hubs = FALSE,   allow.ergodic = FALSE,   return.pt.only = FALSE )"},{"path":"https://diffusr.yinchun.su/reference/random.walk.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Graph diffusion using a Markov random walk — random.walk","text":"p0 \\(n \\times p\\)-dimensional numeric non-negative vector/matrix representing starting distribution Markov chain (need sum one). graph \\(n \\times p\\)-dimensional numeric non-negative adjacence matrix (dgCMatrix) representing graph r scalar \\((0, 1)\\). restart probability Markov random walk restart desired niter maximal number iterations computation Markov chain. thresh reached, niter used stop criterion. thresh threshold breaking iterative computation stationary distribution. absolute difference distribution time point \\(t-1\\) \\(t\\) less thresh, algorithm stops. thresh reached niter, algorithm stops well. .analytical boolean stationary distribution shall computed solving analytical solution rather iteratively correct..hubs TRUE multiplies correction factor nodes, random walk gets biased nodes high degree. case original input matrix normalized : $$ P(j | ) = \\dfrac{1}{\\text{degree}()} \\times   \\min \\left(1, \\dfrac{\\text{degree}()}{\\text{degree}(j)}\\right)$$ Note consider edge weights. allow.ergodic Allow multiple components graph. return.pt.Return pt .","code":""},{"path":"https://diffusr.yinchun.su/reference/random.walk.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Graph diffusion using a Markov random walk — random.walk","text":"returns list following elements  p.inf  stationary distribution numeric vector transition.matrix column normalized transition matrix used         random walk","code":""},{"path":"https://diffusr.yinchun.su/reference/random.walk.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Graph diffusion using a Markov random walk — random.walk","text":"Tong, H., Faloutsos, C., & Pan, J. Y. (2006), Fast random walk restart applications. Koehler, S., Bauer, S., Horn, D., & Robinson, P. N. (2008), Walking interactome prioritization candidate disease genes. American Journal Human Genetics","code":""},{"path":"https://diffusr.yinchun.su/reference/random.walk.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Graph diffusion using a Markov random walk — random.walk","text":"","code":"# count of nodes n <- 5 # starting distribution (has to sum to one) p0    <- as.vector(rmultinom(1, 1, prob=rep(.2, n))) # adjacency matrix (either normalized or not) graph <- matrix(abs(rnorm(n*n)), n, n) # computation of stationary distribution pt    <- random.walk(p0, graph) #> normalizing column vectors!"},{"path":"https://diffusr.yinchun.su/news/index.html","id":"diffusr-v021","dir":"Changelog","previous_headings":"","what":"diffusr v0.2.1","title":"diffusr v0.2.1","text":"Allow sparse matrix input Lint code","code":""},{"path":"https://diffusr.yinchun.su/news/index.html","id":"diffusr-v020","dir":"Changelog","previous_headings":"","what":"diffusr v0.2.0","title":"diffusr v0.2.0","text":"Reorganized code Prepare supporting sparse matrix input","code":""},{"path":"https://diffusr.yinchun.su/news/index.html","id":"diffusr-v014","dir":"Changelog","previous_headings":"","what":"diffusr v0.1.4","title":"diffusr v0.1.4","text":"CRAN release: 2018-05-17 Adds Matrix Suggests","code":""},{"path":"https://diffusr.yinchun.su/news/index.html","id":"diffusr-v013","dir":"Changelog","previous_headings":"","what":"diffusr v0.1.3","title":"diffusr v0.1.3","text":"CRAN release: 2018-04-21 Adds correction hubs Fixes container overflow bug","code":""},{"path":"https://diffusr.yinchun.su/news/index.html","id":"diffusr-v012","dir":"Changelog","previous_headings":"","what":"diffusr v0.1.2","title":"diffusr v0.1.2","text":"CRAN release: 2017-10-29 Removes insulated.heat.diffusion Adds matrix inputs methods","code":""},{"path":"https://diffusr.yinchun.su/news/index.html","id":"diffusr-v011","dir":"Changelog","previous_headings":"","what":"diffusr v0.1.1","title":"diffusr v0.1.1","text":"CRAN release: 2017-06-05 Updated exported function names make registering possible Exchanged S3 S4 classes Check ergodicity random walk Added user interrupt","code":""},{"path":"https://diffusr.yinchun.su/news/index.html","id":"diffusr-v01","dir":"Changelog","previous_headings":"","what":"diffusr v0.1","title":"diffusr v0.1","text":"Markov random walks Laplacian heat diffusion Insulated heat diffusion Nearest neighbor search Matrix utility functions Implementation respective cpp methods Vignette, documentation classes methods License Unit-tests Config, Readme, Travis Lintr Codecov Initial submission CRAN","code":""},{"path":"https://diffusr.yinchun.su/news/index.html","id":"author-0-1","dir":"Changelog","previous_headings":"","what":"Author","title":"diffusr v0.1","text":"Simon Dirmeier simon.dirmeier@gmx.de","code":""}]
